{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/edwardchor/anaconda3/envs/py36/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "plt.ion()\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity='all'\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "import time\n",
    "from graphviz import Digraph\n",
    "import torchvision\n",
    "import scipy.misc as misc\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "import os\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def display(g,img,x,meta):\n",
    "    def tensor2array(x):\n",
    "        return np.array(x)\n",
    "    def variable2array(x):\n",
    "        return np.array(x.data)\n",
    "    def tensors2array(xs):\n",
    "        return [tensor2array(_) for _ in xs]\n",
    "    def variables2array(xs):\n",
    "        return [variable2array(_) for _ in xs]\n",
    "    print(meta)\n",
    "    g,img,x=variables2array([g,img,x])\n",
    "    g=g.reshape((10,10,4))\n",
    "    parsed_g=np.unravel_index(np.argmax(g),g.shape)\n",
    "    print(parsed_g)\n",
    "    plt.figure()\n",
    "    plt.subplot(121)\n",
    "    plt.title('Correct Image')\n",
    "    plt.imshow(img.reshape((56,56)),cmap='gray')\n",
    "    plt.subplot(122)\n",
    "    plt.title('Generated Image')\n",
    "    plt.imshow(x.reshape((56,56)),cmap='gray')\n",
    "    \n",
    "#     print(\"real d_output:{}, fake d_output:{}\".format(d_r, d_f))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "class doodleGenerator:\n",
    "    def __init__(self):\n",
    "        self.edges=['u','r','d','l']\n",
    "        self.MNIST= input_data.read_data_sets(\"../MNIST_data/\", one_hot=True, reshape=[])\n",
    "        self.MNIST_TRAIN_NUM = self.MNIST.train.num_examples\n",
    "        self.MNIST_TRAIN_SET = self.MNIST.train.images, self.MNIST.train.labels, np.argmax(self.MNIST.train.labels, axis=1)\n",
    "        \n",
    "    def getRecordInfo(self,ind):\n",
    "        return self.MNIST_TRAIN_SET[0][ind].reshape((28, 28)), self.MNIST_TRAIN_SET[1][ind], self.MNIST_TRAIN_SET[2][ind]\n",
    "\n",
    "    def fetchRandomPair(self,shape=(10,10,4)):\n",
    "        g = np.zeros(shape=shape)\n",
    "        ind1, ind2 = np.random.randint(0, self.MNIST_TRAIN_NUM), np.random.randint(0, self.MNIST_TRAIN_NUM)\n",
    "        pos = np.random.randint(0, 4)\n",
    "        img1, label1, num1 = self.getRecordInfo(ind1)\n",
    "        img2, label2, num2 = self.getRecordInfo(ind2)\n",
    "        g[num1, num2, pos] = 1\n",
    "        plt.subplot(131)\n",
    "        plt.imshow(img1, cmap='gray')\n",
    "        plt.subplot(132)\n",
    "        plt.imshow(img2, cmap='gray')\n",
    "        plt.subplot(133)\n",
    "        newImg = {\n",
    "            0: np.concatenate([np.zeros((56, 14)), np.concatenate([img2, img1], axis=0), np.zeros((56, 14))], axis=1),\n",
    "            1: np.concatenate([np.zeros((14, 56)), np.concatenate([img1, img2], axis=1), np.zeros((14, 56))], axis=0),\n",
    "            2: np.concatenate([np.zeros((56, 14)), np.concatenate([img1, img2], axis=0), np.zeros((56, 14))], axis=1),\n",
    "            3: np.concatenate([np.zeros((14, 56)), np.concatenate([img2, img1], axis=1), np.zeros((14, 56))], axis=0)\n",
    "        }.get(pos)\n",
    "        return g, newImg\n",
    "\n",
    "\n",
    "    def createDataSet(self,num=100000):\n",
    "        G = []\n",
    "        I = []\n",
    "        for i in range(num):\n",
    "            g, img = self.fetchRandomPair()\n",
    "            G.append(g)\n",
    "            I.append(img)\n",
    "            if i%10000==0:\n",
    "                print(\"{}/100000\".format(i))\n",
    "\n",
    "        I = np.array(I).reshape((num, 56, 56, 1))\n",
    "        G = np.array(G)\n",
    "        np.save('G' + str(num), G)\n",
    "        np.save('I' + str(num), I)\n",
    "        self.TRAIN_SET=[G,I]\n",
    "        return G, I"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Generator,self).__init__()\n",
    "        self.g_conv1=nn.Conv2d(4,8,3,padding=1)\n",
    "        self.z_conv1=nn.Conv2d(16,12,3,padding=1)\n",
    "        self.z_pool1=nn.MaxPool2d(2,2)\n",
    "        self.z_conv2=nn.Conv2d(12,8,7,stride=1)\n",
    "        self.m_fc=nn.Linear(10*10*16,56*56*1)\n",
    "        self.bn_g=nn.modules.BatchNorm2d(8)\n",
    "        self.bn_z=nn.modules.BatchNorm2d(12)\n",
    "\n",
    "    def forward(self, g,z):\n",
    "        g=g.view(-1,4,10,10)\n",
    "        z=z.view(-1,16,32,32)\n",
    "#         print(g.shape,z.shape)\n",
    "        gc1 = self.g_conv1(g)\n",
    "\n",
    "        gc1=F.relu(gc1)\n",
    "#         print('gc1.shape:',gc1.shape)\n",
    "        gc1=self.bn_g(gc1)\n",
    "        zc1 = self.z_pool1(self.z_conv1(z))\n",
    "        zc1=F.relu(zc1)\n",
    "#         print('zc1.shape',zc1.shape)        \n",
    "        zc1=self.bn_z(zc1)\n",
    "        zc2 = self.z_conv2(zc1)\n",
    "        zc2=F.relu(zc2)\n",
    "#         print('zc2.shape',zc2.shape)        \n",
    "        merged = torch.cat([gc1, zc2], 1)\n",
    "#         print('merged.shape',merged.shape)\n",
    "        merged_r=merged.view(-1,16*10*10)\n",
    "        o = self.m_fc(merged_r)\n",
    "#         print('output.shape',o.shape)\n",
    "        return o.view((-1,1,56, 56))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Discriminator,self).__init__()\n",
    "        self.g_conv1 = nn.Conv2d(4, 8, 3, padding=1)\n",
    "        self.x_conv1 = nn.Conv2d(1, 16, 3, padding=0)\n",
    "        self.x_pool1 = nn.MaxPool2d(2, 2)\n",
    "        self.x_conv2 = nn.Conv2d(16, 64, 8)\n",
    "\n",
    "        self.m_conv = nn.Conv2d(72, 128, 3)\n",
    "        self.m_fc1 = nn.Linear(1 *128*8*8, 2048)\n",
    "        self.m_fc2 = nn.Linear(2048, 256)\n",
    "        self.m_fc3 = nn.Linear(256, 2)\n",
    "        self.d_softmax=nn.Softmax()\n",
    "        \n",
    "        self.bn_g=nn.modules.BatchNorm2d(num_features=8)\n",
    "        self.bn_x=nn.modules.BatchNorm2d(num_features=16)\n",
    "\n",
    "    def forward(self, g,x):\n",
    "        g=g.view(-1,4,10,10)\n",
    "        x=x.view(-1,1,56,56)\n",
    "        gc1 = self.g_conv1(g)\n",
    "        gc1=F.relu(gc1)\n",
    "        gc1=self.bn_g(gc1)\n",
    "#         print('gc1.shape:',gc1.shape)\n",
    "        xc1=self.x_conv1(x)\n",
    "#         print('xc1.shape:',xc1.shape)\n",
    "        xp1=F.relu(self.x_pool1(xc1))\n",
    "        xp1=self.bn_x(xp1)\n",
    "#         print('xp1.shape:',xp1.shape)\n",
    "        xc2=self.x_conv2(xp1)\n",
    "#         print('xc2.shape:',xc2.shape)\n",
    "        xp2=F.relu(self.x_pool1(xc2))\n",
    "#         print('xp2.shape:',xp2.shape)\n",
    "        merged = torch.cat([xp2, gc1], 1)\n",
    "#         print('merged.shape:',merged.shape)\n",
    "        mc = self.m_conv(merged)\n",
    "#         print('mc.shape:',mc.shape)\n",
    "        mc=mc.view(-1,128*8*8)\n",
    "        m_fc1=self.m_fc1(mc)\n",
    "#         print('m_fc1.shape',m_fc1.shape)\n",
    "        m_fc2=self.m_fc2(m_fc1)\n",
    "#         print('m_fc2.shape',m_fc2.shape)\n",
    "        m_fc3 = self.m_fc3(m_fc2)\n",
    "#         print('m_fc3.shape',m_fc3.shape)\n",
    "        return self.d_softmax(m_fc3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class cDCGAN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(cDCGAN, self).__init__()\n",
    "        self.G=Generator()\n",
    "        self.D=Discriminator()\n",
    "        self.G_LOSS=nn.CrossEntropyLoss()\n",
    "        self.rD_LOSS=nn.CrossEntropyLoss()\n",
    "        self.fD_LOSS=nn.CrossEntropyLoss()\n",
    "        self.use_gpu=torch.cuda.is_available()\n",
    "        self.lr=0.001\n",
    "        self.batch_size=100\n",
    "        self.iters=1000\n",
    "        self.epoch=200\n",
    "        \n",
    "        self.SAVE_DIR='./out/2/'\n",
    "        try:\n",
    "            os.makedirs(self.SAVE_DIR)\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "    def setTrainParas(self,batch_num,lr,iters,epoch):\n",
    "        self.lr,self.batch_num,self.iters,self.epoch=lr,batch_num,iters,epoch\n",
    "\n",
    "    def feedData(self,GI,ratio=0.8):\n",
    "        G,I=GI\n",
    "        num_of_records=G.shape[0]\n",
    "        \n",
    "        self.dataLoader={\n",
    "            'train':[],\n",
    "            'test':[]\n",
    "        }\n",
    "        batch_num=num_of_records//self.batch_size\n",
    "        print(\"{} records, {} batches of size {} each\".format(num_of_records,batch_num,self.batch_size))\n",
    "        cur_batch_G=[]\n",
    "        cur_batch_I = []\n",
    "        batched_data=[]\n",
    "        for i in range(num_of_records):\n",
    "            cur_batch_G.append(G[i])\n",
    "            cur_batch_I.append(I[i])\n",
    "            if i %self.batch_size==self.batch_size-1:\n",
    "                batched_data.append((np.array(cur_batch_G),np.array(cur_batch_I)))\n",
    "                cur_batch_G=[]\n",
    "                cur_batch_I=[]\n",
    "        self.dataLoader['train']=batched_data[:int(batch_num*0.8)]\n",
    "        self.dataLoader['test']=batched_data[int(batch_num*0.8):]\n",
    "        print(self.dataLoader['train'][0][0][0].shape,self.dataLoader['train'][0][0][1].shape)\n",
    "    def convert2Cuda(self,l):\n",
    "        return [_.cuda() for _ in l]\n",
    "            \n",
    "    def trainNetwork(self):\n",
    "        G_optimizer=optim.SGD(self.G.parameters(),lr=self.lr,momentum=0.9)\n",
    "        D_optimizer=optim.SGD(self.D.parameters(),lr=self.lr,momentum=0.9)\n",
    "\n",
    "        for  e in range(self.epoch):\n",
    "            G_losses, D_losses = [], []\n",
    "            eporch_starttime=time.time()\n",
    "            print('Epoch {}/{}'.format(e+1,self.epoch))\n",
    "            print(\"-\"*10)\n",
    "            for phase in ['train','test']:\n",
    "                print('Current Phase:{}'.format(phase))\n",
    "\n",
    "                if phase=='train':\n",
    "                    G_optimizer.step()\n",
    "                    D_optimizer.step()\n",
    "                    self.D.train(True)\n",
    "                    self.G.train(True)\n",
    "                else:\n",
    "                    self.D.train(False)\n",
    "                    self.G.train(False)\n",
    "\n",
    "                for i, data in enumerate(self.dataLoader[phase],0):\n",
    "                    z=torch.randn((self.batch_size,32,32,16))\n",
    "                \n",
    "                    g,img=data\n",
    "                    G_optimizer.zero_grad()\n",
    "                    D_optimizer.zero_grad()\n",
    "                    g,img,z=Variable(torch.Tensor(g)),Variable(torch.Tensor(img)),Variable(torch.Tensor(z))\n",
    "                    rd_label=Variable(torch.LongTensor(np.zeros((self.batch_size))),requires_grad=False)\n",
    "#                     rd_label.requires_grad=False\n",
    "                    fd_label=Variable(torch.LongTensor(np.ones((self.batch_size))),requires_grad=False)\n",
    "#                     fd_label.requires_grad=False\n",
    "\n",
    "                    if self.use_gpu:\n",
    "                        g,img,z,rd_label,fd_label,self.convert2Cuda([g,img,z,rd_label,fd_label])\n",
    "                    \n",
    "                    x=self.G(g,z)\n",
    "                    r_d_out=self.D(g,img)\n",
    "                    f_d_out=self.D(g,x)\n",
    "                    \n",
    "                    \n",
    "                    real_d_loss=self.rD_LOSS(r_d_out,rd_label)\n",
    "                    fake_d_loss=self.fD_LOSS(f_d_out,fd_label)\n",
    "                    d_loss=real_d_loss+fake_d_loss\n",
    "                    g_loss=self.G_LOSS(f_d_out,rd_label)\n",
    "\n",
    "                    if i%50==0:\n",
    "                        ind=np.random.randint(0,self.batch_size)\n",
    "                        print(\"{}  G_loss: {}, D_loss:{}\".format(phase,g_loss.data[0],d_loss.data[0]))\n",
    "#                         display(g,img,x,meta=' ')\n",
    "                        misc.imsave(self.SAVE_DIR+'{}_{}_{}_img.png'.format(e,phase,i),np.array(img[ind].data).reshape((56,56)))\n",
    "                        misc.imsave(self.SAVE_DIR+'{}_{}_{}_x.png'.format(e,phase,i),np.array(x[ind].data).reshape((56,56)))\n",
    "                    G_losses.append(g_loss)\n",
    "                    D_losses.append(d_loss)\n",
    "                    if phase=='train':\n",
    "                        g_loss.backward(retain_graph=True)\n",
    "                        G_optimizer.step()\n",
    "                        d_loss.backward()\n",
    "                        D_optimizer.step()\n",
    "                \n",
    "            if e%50==9:\n",
    "                self.saveCheckpoint('{}'.format(e))\n",
    "    def saveCheckpoint(self,e):\n",
    "        self.D.save_state_dict('D_temp{}.pth.tar'.format(e))\n",
    "        self.G.save_state_dict('G_temp{}.pth.tar'.format(e))\n",
    "\n",
    "    def loadCheckpoint(self,e):\n",
    "        self.D.load_state_dict(torch.load('D_temp{}.pth.tar'.format(e)))\n",
    "        self.G.load_state_dict(torch.load('G_temp{}.pth.tar'.format(e)))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100000 records, 1000 batches of size 100 each\n",
      "(10, 10, 4) (10, 10, 4)\n",
      "Epoch 1/200\n",
      "----------\n",
      "Current Phase:train\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/edwardchor/anaconda3/envs/py36/lib/python3.6/site-packages/ipykernel_launcher.py:45: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train  G_loss: 0.657154381275177, D_loss:1.0658833980560303\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-9341043c3210>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mdcgan\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeedData\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mdcgan\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloadCheckpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m''\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mdcgan\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainNetwork\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-10-21d95c444c18>\u001b[0m in \u001b[0;36mtrainNetwork\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     86\u001b[0m                     \u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mG\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m                     \u001b[0mr_d_out\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mD\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 88\u001b[0;31m                     \u001b[0mf_d_out\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mD\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/py36/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    355\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    356\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 357\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    358\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    359\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-8-7abda25e08c1>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, g, x)\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0mxp1\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbn_x\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxp1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;31m#         print('xp1.shape:',xp1.shape)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m         \u001b[0mxc2\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx_conv2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxp1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m \u001b[0;31m#         print('xc2.shape:',xc2.shape)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m         \u001b[0mxp2\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx_pool1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxc2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/py36/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    355\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    356\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 357\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    358\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    359\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/py36/lib/python3.6/site-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    280\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    281\u001b[0m         return F.conv2d(input, self.weight, self.bias, self.stride,\n\u001b[0;32m--> 282\u001b[0;31m                         self.padding, self.dilation, self.groups)\n\u001b[0m\u001b[1;32m    283\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    284\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# dg=doodleGenerator()\n",
    "# data=dg.createDataSet()\n",
    "data=[np.load('G100000.npy'),np.load('I100000.npy')]\n",
    "dcgan=cDCGAN()\n",
    "dcgan.feedData(data)\n",
    "dcgan.loadCheckpoint('')\n",
    "dcgan.trainNetwork()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 461,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def save_checkpoint(state, is_best, filename='checkpoint.pth.tar'):\n",
    "    torch.save(state, filename)\n",
    "    if is_best:\n",
    "        shutil.copyfile(filename, 'model_best.pth.tar')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "144px",
    "left": "1128px",
    "right": "20px",
    "top": "37.6094px",
    "width": "350px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
